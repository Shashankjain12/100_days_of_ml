{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shashank/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"data.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(\"quality\",axis=1)\n",
    "y=dataset[\"quality\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm=[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "dataset[cols_to_norm]=dataset[cols_to_norm].apply(lambda x:(x-x.min())/(x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.150183</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.259036</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.246988</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.031359</td>\n",
       "      <td>0.125290</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.232019</td>\n",
       "      <td>0.146327</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.222892</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.153132</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.160279</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.432692</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.286043</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>0.135889</td>\n",
       "      <td>0.378190</td>\n",
       "      <td>0.252362</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>0.109697</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.059347</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.153132</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>0.088490</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.105828</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.161751</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.059347</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.153132</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.035276</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.215777</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.016871</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.135889</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.192878</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.368910</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.246988</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.188153</td>\n",
       "      <td>0.547564</td>\n",
       "      <td>0.161751</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.114983</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.124233</td>\n",
       "      <td>0.124629</td>\n",
       "      <td>0.104530</td>\n",
       "      <td>0.306265</td>\n",
       "      <td>0.173318</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.243619</td>\n",
       "      <td>0.067284</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.059816</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>0.266821</td>\n",
       "      <td>0.118180</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.198795</td>\n",
       "      <td>0.145706</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.176403</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>0.221154</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>0.035608</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.091961</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.049933</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.653226</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.246988</td>\n",
       "      <td>0.180982</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.167247</td>\n",
       "      <td>0.394432</td>\n",
       "      <td>0.175631</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.062315</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.064199</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.110083</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.055749</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.250580</td>\n",
       "      <td>0.081164</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>0.110854</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.013937</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.100829</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.150954</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.150954</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>0.171012</td>\n",
       "      <td>0.062315</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.083086</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.341067</td>\n",
       "      <td>0.091190</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.102410</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.202091</td>\n",
       "      <td>0.322506</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.118098</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>0.382831</td>\n",
       "      <td>0.150569</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.150954</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.078221</td>\n",
       "      <td>0.056380</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.259861</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.445455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.109049</td>\n",
       "      <td>0.041835</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.125436</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.119337</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>0.171012</td>\n",
       "      <td>0.062315</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.221154</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.080119</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.211137</td>\n",
       "      <td>0.043763</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.125436</td>\n",
       "      <td>0.259861</td>\n",
       "      <td>0.069983</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>0.113168</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.076655</td>\n",
       "      <td>0.192575</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.113497</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.368910</td>\n",
       "      <td>0.150183</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.114458</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.236659</td>\n",
       "      <td>0.104685</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.234339</td>\n",
       "      <td>0.030461</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.069686</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.307692          0.186275     0.216867        0.308282   0.106825   \n",
       "1          0.240385          0.215686     0.204819        0.015337   0.118694   \n",
       "2          0.413462          0.196078     0.240964        0.096626   0.121662   \n",
       "3          0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "4          0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "5          0.413462          0.196078     0.240964        0.096626   0.121662   \n",
       "6          0.230769          0.235294     0.096386        0.098160   0.106825   \n",
       "7          0.307692          0.186275     0.216867        0.308282   0.106825   \n",
       "8          0.240385          0.215686     0.204819        0.015337   0.118694   \n",
       "9          0.413462          0.137255     0.259036        0.013804   0.103858   \n",
       "10         0.413462          0.186275     0.246988        0.013037   0.071217   \n",
       "11         0.461538          0.147059     0.240964        0.055215   0.077151   \n",
       "12         0.394231          0.098039     0.222892        0.009202   0.091988   \n",
       "13         0.269231          0.078431     0.240964        0.013804   0.103858   \n",
       "14         0.432692          0.333333     0.373494        0.286043   0.091988   \n",
       "15         0.269231          0.088235     0.228916        0.013804   0.068249   \n",
       "16         0.240385          0.392157     0.024096        0.007669   0.109792   \n",
       "17         0.230769          0.568627     0.289157        0.009202   0.059347   \n",
       "18         0.346154          0.254902     0.253012        0.007669   0.071217   \n",
       "19         0.259615          0.225490     0.084337        0.105828   0.103858   \n",
       "20         0.230769          0.568627     0.289157        0.009202   0.059347   \n",
       "21         0.250000          0.225490     0.228916        0.035276   0.086053   \n",
       "22         0.288462          0.176471     0.253012        0.016871   0.118694   \n",
       "23         0.365385          0.578431     0.084337        0.013804   0.192878   \n",
       "24         0.269231          0.186275     0.246988        0.010736   0.127596   \n",
       "25         0.307692          0.166667     0.192771        0.128834   0.109792   \n",
       "26         0.298077          0.156863     0.210843        0.006135   0.127596   \n",
       "27         0.307692          0.196078     0.234940        0.124233   0.124629   \n",
       "28         0.346154          0.186275     0.289157        0.007669   0.112760   \n",
       "29         0.326923          0.235294     0.216867        0.021472   0.071217   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4868       0.192308          0.147059     0.186747        0.059816   0.109792   \n",
       "4869       0.269231          0.156863     0.198795        0.145706   0.068249   \n",
       "4870       0.221154          0.235294     0.168675        0.092025   0.035608   \n",
       "4871       0.115385          0.117647     0.240964        0.019939   0.017804   \n",
       "4872       0.211538          0.333333     0.246988        0.180982   0.068249   \n",
       "4873       0.182692          0.127451     0.192771        0.015337   0.062315   \n",
       "4874       0.173077          0.117647     0.216867        0.029141   0.115727   \n",
       "4875       0.346154          0.137255     0.156627        0.009202   0.077151   \n",
       "4876       0.230769          0.294118     0.253012        0.029141   0.086053   \n",
       "4877       0.201923          0.450980     0.000000        0.003067   0.068249   \n",
       "4878       0.230769          0.441176     0.012048        0.004601   0.077151   \n",
       "4879       0.269231          0.254902     0.240964        0.115031   0.109792   \n",
       "4880       0.269231          0.254902     0.240964        0.115031   0.109792   \n",
       "4881       0.115385          0.151961     0.162651        0.171012   0.062315   \n",
       "4882       0.163462          0.235294     0.078313        0.010736   0.083086   \n",
       "4883       0.105769          0.382353     0.102410        0.019939   0.077151   \n",
       "4884       0.259615          0.245098     0.228916        0.118098   0.115727   \n",
       "4885       0.269231          0.254902     0.240964        0.115031   0.109792   \n",
       "4886       0.230769          0.127451     0.168675        0.078221   0.056380   \n",
       "4887       0.230769          0.323529     0.132530        0.019939   0.041543   \n",
       "4888       0.288462          0.137255     0.216867        0.009202   0.127596   \n",
       "4889       0.105769          0.151961     0.162651        0.171012   0.062315   \n",
       "4890       0.221154          0.254902     0.174699        0.024540   0.080119   \n",
       "4891       0.182692          0.127451     0.192771        0.004601   0.086053   \n",
       "4892       0.259615          0.147059     0.228916        0.010736   0.068249   \n",
       "4893       0.230769          0.127451     0.174699        0.015337   0.089021   \n",
       "4894       0.269231          0.235294     0.216867        0.113497   0.112760   \n",
       "4895       0.259615          0.156863     0.114458        0.009202   0.094955   \n",
       "4896       0.163462          0.205882     0.180723        0.007669   0.038576   \n",
       "4897       0.211538          0.127451     0.228916        0.003067   0.032641   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0                0.149826              0.373550  0.267785  0.254545   \n",
       "1                0.041812              0.285383  0.132832  0.527273   \n",
       "2                0.097561              0.204176  0.154039  0.490909   \n",
       "3                0.156794              0.410673  0.163678  0.427273   \n",
       "4                0.156794              0.410673  0.163678  0.427273   \n",
       "5                0.097561              0.204176  0.154039  0.490909   \n",
       "6                0.097561              0.294664  0.150183  0.418182   \n",
       "7                0.149826              0.373550  0.267785  0.254545   \n",
       "8                0.041812              0.285383  0.132832  0.527273   \n",
       "9                0.090592              0.278422  0.128976  0.454545   \n",
       "10               0.031359              0.125290  0.071139  0.245455   \n",
       "11               0.052265              0.232019  0.146327  0.381818   \n",
       "12               0.048780              0.153132  0.094274  0.418182   \n",
       "13               0.160279              0.310905  0.078851  0.745455   \n",
       "14               0.135889              0.378190  0.252362  0.236364   \n",
       "15               0.090592              0.238979  0.082707  0.481818   \n",
       "16               0.097561              0.208817  0.109697  0.472727   \n",
       "17               0.094077              0.153132  0.040293  0.554545   \n",
       "18               0.052265              0.375870  0.088490  0.363636   \n",
       "19               0.111498              0.287703  0.161751  0.454545   \n",
       "20               0.094077              0.153132  0.040293  0.554545   \n",
       "21               0.059233              0.215777  0.078851  0.409091   \n",
       "22               0.135889              0.262181  0.113553  0.681818   \n",
       "23               0.080139              0.368910  0.127048  0.300000   \n",
       "24               0.048780              0.308585  0.154039  0.636364   \n",
       "25               0.188153              0.547564  0.161751  0.481818   \n",
       "26               0.114983              0.317865  0.113553  0.663636   \n",
       "27               0.104530              0.306265  0.173318  0.600000   \n",
       "28               0.052265              0.285383  0.082707  0.427273   \n",
       "29               0.121951              0.243619  0.067284  0.345455   \n",
       "...                   ...                   ...       ...       ...   \n",
       "4868             0.139373              0.266821  0.118180  0.536364   \n",
       "4869             0.020906              0.167053  0.176403  0.427273   \n",
       "4870             0.094077              0.285383  0.091961  0.390909   \n",
       "4871             0.062718              0.206497  0.049933  0.590909   \n",
       "4872             0.167247              0.394432  0.175631  0.381818   \n",
       "4873             0.108014              0.262181  0.064199  0.554545   \n",
       "4874             0.048780              0.269142  0.110083  0.700000   \n",
       "4875             0.055749              0.204176  0.102950  0.363636   \n",
       "4876             0.111498              0.250580  0.081164  0.581818   \n",
       "4877             0.034843              0.169374  0.110854  0.481818   \n",
       "4878             0.013937              0.167053  0.100829  0.472727   \n",
       "4879             0.229965              0.373550  0.150954  0.390909   \n",
       "4880             0.229965              0.373550  0.150954  0.390909   \n",
       "4881             0.111498              0.252900  0.159823  0.318182   \n",
       "4882             0.149826              0.341067  0.091190  0.490909   \n",
       "4883             0.202091              0.322506  0.048776  0.500000   \n",
       "4884             0.229965              0.382831  0.150569  0.381818   \n",
       "4885             0.229965              0.373550  0.150954  0.390909   \n",
       "4886             0.149826              0.259861  0.088105  0.445455   \n",
       "4887             0.010453              0.109049  0.041835  0.290909   \n",
       "4888             0.125436              0.273782  0.119337  0.290909   \n",
       "4889             0.111498              0.252900  0.159823  0.318182   \n",
       "4890             0.080139              0.211137  0.043763  0.309091   \n",
       "4891             0.125436              0.259861  0.069983  0.472727   \n",
       "4892             0.094077              0.238979  0.113168  0.518182   \n",
       "4893             0.076655              0.192575  0.077694  0.500000   \n",
       "4894             0.191638              0.368910  0.150183  0.390909   \n",
       "4895             0.097561              0.236659  0.104685  0.245455   \n",
       "4896             0.062718              0.234339  0.030461  0.563636   \n",
       "4897             0.069686              0.206497  0.044342  0.490909   \n",
       "\n",
       "      sulphates   alcohol   quality  \n",
       "0      0.267442  0.129032  0.500000  \n",
       "1      0.313953  0.241935  0.500000  \n",
       "2      0.255814  0.338710  0.500000  \n",
       "3      0.209302  0.306452  0.500000  \n",
       "4      0.209302  0.306452  0.500000  \n",
       "5      0.255814  0.338710  0.500000  \n",
       "6      0.290698  0.258065  0.500000  \n",
       "7      0.267442  0.129032  0.500000  \n",
       "8      0.313953  0.241935  0.500000  \n",
       "9      0.267442  0.483871  0.500000  \n",
       "10     0.395349  0.645161  0.333333  \n",
       "11     0.360465  0.274194  0.333333  \n",
       "12     0.476744  0.451613  0.333333  \n",
       "13     0.348837  0.709677  0.666667  \n",
       "14     0.523256  0.274194  0.333333  \n",
       "15     0.383721  0.548387  0.666667  \n",
       "16     0.162791  0.258065  0.500000  \n",
       "17     0.197674  0.774194  0.833333  \n",
       "18     0.360465  0.532258  0.500000  \n",
       "19     0.325581  0.241935  0.333333  \n",
       "20     0.197674  0.774194  0.833333  \n",
       "21     0.151163  0.483871  0.666667  \n",
       "22     0.302326  0.403226  0.833333  \n",
       "23     0.337209  0.209677  0.333333  \n",
       "24     0.290698  0.322581  0.500000  \n",
       "25     0.325581  0.387097  0.500000  \n",
       "26     0.255814  0.322581  0.500000  \n",
       "27     0.360465  0.403226  0.500000  \n",
       "28     0.313953  0.580645  0.500000  \n",
       "29     0.569767  0.693548  0.666667  \n",
       "...         ...       ...       ...  \n",
       "4868   0.488372  0.451613  0.500000  \n",
       "4869   0.337209  0.290323  0.500000  \n",
       "4870   0.162791  0.556452  0.666667  \n",
       "4871   0.383721  0.653226  0.500000  \n",
       "4872   0.441860  0.274194  0.333333  \n",
       "4873   0.348837  0.629032  0.500000  \n",
       "4874   0.313953  0.322581  0.500000  \n",
       "4875   0.220930  0.274194  0.500000  \n",
       "4876   0.430233  0.580645  0.666667  \n",
       "4877   0.162791  0.129032  0.333333  \n",
       "4878   0.151163  0.241935  0.166667  \n",
       "4879   0.325581  0.247312  0.500000  \n",
       "4880   0.325581  0.247312  0.500000  \n",
       "4881   0.325581  0.225806  0.500000  \n",
       "4882   0.186047  0.435484  0.333333  \n",
       "4883   0.151163  0.564516  0.500000  \n",
       "4884   0.325581  0.258065  0.333333  \n",
       "4885   0.325581  0.250000  0.500000  \n",
       "4886   1.000000  0.669355  0.666667  \n",
       "4887   0.662791  0.806452  0.666667  \n",
       "4888   0.372093  0.193548  0.333333  \n",
       "4889   0.325581  0.225806  0.500000  \n",
       "4890   0.255814  0.612903  0.500000  \n",
       "4891   0.279070  0.419355  0.500000  \n",
       "4892   0.372093  0.274194  0.333333  \n",
       "4893   0.325581  0.516129  0.500000  \n",
       "4894   0.279070  0.258065  0.333333  \n",
       "4895   0.279070  0.225806  0.500000  \n",
       "4896   0.186047  0.774194  0.666667  \n",
       "4897   0.116279  0.612903  0.500000  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_acidity=tf.feature_column.numeric_column(\"fixed acidity\")\n",
    "volatile_acidity=tf.feature_column.numeric_column(\"volatile acidity\")\n",
    "citric_acid=tf.feature_column.numeric_column(\"citric acid\")\n",
    "residual_sugar=tf.feature_column.numeric_column(\"residual sugar\")\n",
    "chlorides=tf.feature_column.numeric_column(\"chlorides\")\n",
    "free_sulfur_dioxide=tf.feature_column.numeric_column(\"free sulfur dioxide\")\n",
    "total_sulfur_dioxide=tf.feature_column.numeric_column(\"total sulfur dioxide\")\n",
    "density=tf.feature_column.numeric_column(\"density\")\n",
    "pH=tf.feature_column.numeric_column(\"pH\")\n",
    "sulphates=tf.feature_column.numeric_column(\"sulphates\")\n",
    "alcohol=tf.feature_column.numeric_column(\"alcohol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fun= tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow_estimator.python.estimator.inputs.pandas_io.pandas_input_fn.<locals>.input_fn>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow_estimator.python.estimator.inputs.pandas_io.pandas_input_fn.<locals>.input_fn>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fn= tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=10,shuffle=True)\n",
    "train_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_fn= tf.estimator.inputs.pandas_input_fn(x=X_test,y=y_test,batch_size=100,num_epochs=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 22:15:03.310540 139671609087808 estimator.py:1799] Using temporary folder as model directory: /tmp/tmpjupcnpmw\n"
     ]
    }
   ],
   "source": [
    "feat_cols=[fixed_acidity,volatile_acidity,citric_acid,residual_sugar,chlorides,free_sulfur_dioxide,total_sulfur_dioxide,density,pH,sulphates,alcohol]\n",
    "model=tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'linear/linear_model/citric acid/weights/part_0/PartitionedInitializer' is not a valid scope name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ab9b05078956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1167\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1169\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1170\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    786\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m           sparse_combiner=sparse_combiner)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     super(LinearClassifier, self).__init__(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config, sparse_combiner)\u001b[0m\n\u001b[1;32m    536\u001b[0m           \u001b[0msparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m           )\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m       optimizer = optimizers.get_optimizer_instance(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36mlinear_logit_fn\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0msparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m           name='linear_model')\n\u001b[0;32m--> 347\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m       \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    702\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \"\"\"\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m           \u001b[0;31m# Explicitly pass the learning phase placeholder to `call` if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m           \u001b[0;31m# the `training` argument was left unspecified by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    527\u001b[0m               \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m               \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m               trainable=self.trainable)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m       \u001b[0;31m# Create a bias variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mcreate_variable\u001b[0;34m(self, feature_column, name, shape, dtype, trainable, use_resource, initializer)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# specifying a default partitioner for an entire layer. In that case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# the default getter for Layers should work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         getter=variable_scope.get_variable)\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cols_to_vars_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    620\u001b[0m     new_variable = getter(\n\u001b[1;32m    621\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1480\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1221\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    453\u001b[0m               \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m               \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m               aggregation=aggregation)\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;31m# Special case for partitioned variable to allow reuse without having to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_partitioned_variable\u001b[0;34m(self, name, partitioner, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    723\u001b[0m           full_shape=shape.as_list(), var_offset=var_offset)\n\u001b[1;32m    724\u001b[0m       \u001b[0mvar_full_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s/part_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_full_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/PartitionedInitializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;31m# Create the tensor to initialize the variable with default value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6348\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6351\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4171\u001b[0m         \u001b[0;31m# op name regex, which constrains the initial character.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_VALID_OP_NAME_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4173\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%s' is not a valid scope name\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4174\u001b[0m     \u001b[0mold_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Both for name=None and name=\"\" we re-set to empty scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'linear/linear_model/citric acid/weights/part_0/PartitionedInitializer' is not a valid scope name"
     ]
    }
   ],
   "source": [
    "model.train(input_fn=input_fun,steps=1000)\n",
    "results = model.evaluate(eval_input_fn)\n",
    "predictions = model.predict(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.2 ,  0.26,  0.32, ...,  3.23,  0.49, 10.5 ],\n",
       "       [ 5.4 ,  0.29,  0.38, ...,  3.28,  0.36, 12.4 ],\n",
       "       [ 6.5 ,  0.46,  0.31, ...,  3.26,  0.6 , 11.5 ],\n",
       "       ...,\n",
       "       [ 7.9 ,  0.33,  0.28, ...,  3.15,  0.38,  8.8 ],\n",
       "       [ 8.9 ,  0.26,  0.33, ...,  3.13,  0.46, 10.8 ],\n",
       "       [ 7.9 ,  0.51,  0.34, ...,  3.09,  0.51, 10.  ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
